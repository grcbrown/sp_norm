sci_y <- table(enroll)[2,2]
sci_y_sim <- c()
enroll_sim <- enroll
for (i in 1:nrep) {
enroll_sim$Major <- sample(enroll_sim$Major)
sci_y_sim <- c(sci_y_sim, table(enroll_sim)[2,2])
}
p_permute <- sum(sci_y_sim>=sci_y)/nrep + sum(sci_y_sim<=-sci_y)/nrep
print("The p-value is"); p_permute
knitr::opts_chunk$set(echo = TRUE)
b0 <- -15.043
b1 <- 0.232
x <- c(31, 50, 75)
prob_success <- function(x) {
pi.hat <- (exp(b0+b1*x))/(1+exp(b0+b1*x))
}
pi.hat
b0 <- -15.043
b1 <- 0.232
x <- c(31, 50, 75)
prob_success <- function(x) {
pi.hat <- (exp(b0+b1*x))/(1+exp(b0+b1*x))
return(pi.hat)
}
pi.hat
b0 <- -15.043
b1 <- 0.232
x <- c(31, 50, 75)
prob_success <- function(x) {
pi.hat <- (exp(b0+b1*x))/(1+exp(b0+b1*x))
return(pi.hat)
}
b0 <- -15.043
b1 <- 0.232
prob_success <- function(x) {
pi.hat <- (exp(b0+b1*x))/(1+exp(b0+b1*x))
return(pi.hat)
}
b0 <- -15.043
b1 <- 0.232
prob_success <- function(x) {
pi.hat <- (exp(b0+b1*x))/(1+exp(b0+b1*x))
return(pi.hat)
}
prob_success(31)
b0 <- -15.043
b1 <- 0.232
prob_success <- function(x) {
pi.hat <- (exp(b0+b1*x))/(1+exp(b0+b1*x))
return(pi.hat)
}
print("The probability that a launch has no O-ring damage at 31 degrees F"); prob_success(31)
print("The probability that a launch has no O-ring damage at 50 degrees F"); prob_success(50)
print("The probability that a launch has no O-ring damage at 75 degrees F"); prob_success(75)
odds <- function(x) {
y <- exp(b0+b1*x)
return(y)
}
print("The odds of a launch with no O-ring damage at 60 degrees F"); odds(60)
print("The odds of a launch with no O-ring damage at 70 degrees F"); odds(70)
odds <- function(x) {
pi.hat <- (exp(b0+b1*x))/(1+exp(b0+b1*x))
y <- pi.hat/(1-pi.hat)
return(y)
}
print("The odds of a launch with no O-ring damage at 60 degrees F"); odds(60)
print("The odds of a launch with no O-ring damage at 70 degrees F"); odds(70)
exp(b1*10)
exp(b1*10)
exp(b1*10)
3.310171/0.3253024
exp(b1*10)
exp(b1)^10
exp(b1*10)
## check
odds(70)/odds(60)
odds(60)-odds(59)
odds(52)-odds(51)
odds(31)/odds(60)
odds(60)/odds(31)
odds(60)/odds(31)
exp(b1*(60-31))
odds_ratio <- exp(b1*(60-31))
Z.star <- 1.96
sd(b1)
odds_ratio <- exp(b1*(60-31))
Z.star <- 1.96
se.b1 <- 0.108
exp(b1 - Z.star*se.b1)
exp(b1 + Z.star*se.b1)
odds_ratio <- exp(b1*(60-31))
Z.star <- 1.96
se.b1 <- 0.108
exp(b1 - Z.star*se.b1)^(60-31)
exp(b1 + Z.star*se.b1)^(60-31)
odds_ratio <- exp(b1*(60-31))
print("The odds ratio of a successful launch between 31 and 60 degrees F"); odds_ratio
Z.star <- 1.96
se.b1 <- 0.108
exp(b1 - Z.star*se.b1)^(60-31)
exp(b1 + Z.star*se.b1)^(60-31)
read.csv("C7 Birdnest.csv")
library(readr)
C7_Birdnest <- read_csv("Documents/School/Fall 2021/STATS 403/LabWorkspace/C7 Birdnest.csv")
View(C7_Birdnest)
# load dataset from personal library
library(readr)
C7_Birdnest <- read_csv("Documents/School/Fall 2021/STATS 403/LabWorkspace/C7 Birdnest.csv")
# load renamed dataset from personal library
C7_Birdnest <- read.csv("C7_Birdnest.csv")
# load renamed dataset from personal library
C7_Birdnest <- read.csv("C7_Birdnest.csv")
na.omit(C7_Birdnest$Length)
# load renamed dataset from personal library
C7_Birdnest <- read.csv("C7_Birdnest.csv")
summary(C7_Birdnest$Length)
C7_Birdnest$Length <- as.double(C7_Birdnest$Length)
C7_Birdnest$Length <- na.omit(C7_Birdnest$Length)
# load renamed dataset from personal library
C7_Birdnest <- read.csv("C7_Birdnest.csv")
C7_Birdnest$Length <- as.double(C7_Birdnest$Length)
C7_Birdnest <- na.omit(C7_Birdnest$Length)
# load renamed dataset from personal library
C7_Birdnest <- read.csv("C7_Birdnest.csv")
C7_Birdnest$Length <- as.double(C7_Birdnest$Length)
# load renamed dataset from personal library
C7_Birdnest <- read.csv("C7_Birdnest.csv")
C7_Birdnest$Length <- as.double(C7_Birdnest$Length)
birdnest <- c(length = na.omit(C7_Birdnest$Length), closed = C7_Birdnest$Closed.)
# load renamed dataset from personal library
C7_Birdnest <- read.csv("C7_Birdnest.csv")
C7_Birdnest$Length <- as.double(C7_Birdnest$Length)
birdnest <- c(length = na.omit(C7_Birdnest$Length), closed = C7_Birdnest$Closed.)
birdnest
# load renamed dataset from personal library
C7_Birdnest <- read.csv("C7_Birdnest.csv")
C7_Birdnest$Length <- as.double(C7_Birdnest$Length)
C7_Birdnest$Closed. <- as.double(C7_Birdnest$Closed.)
birdnest <- c(length = na.omit(C7_Birdnest$Length), closed = C7_Birdnest$Closed.)
# load renamed dataset from personal library
C7_Birdnest <- read.csv("C7_Birdnest.csv")
C7_Birdnest$Length <- as.double(C7_Birdnest$Length)
C7_Birdnest$Closed. <- as.double(C7_Birdnest$Closed.)
birdnest <- c(length = na.omit(C7_Birdnest$Length), closed = C7_Birdnest$Closed.)
birdnest
# load renamed dataset from personal library
C7_Birdnest <- read.csv("C7_Birdnest.csv")
C7_Birdnest$Length <- as.double(C7_Birdnest$Length)
C7_Birdnest$Closed. <- as.double(C7_Birdnest$Closed.)
birdnest <- data.frame(length = na.omit(C7_Birdnest$Length), closed = C7_Birdnest$Closed.)
# load renamed dataset from personal library
C7_Birdnest <- read.csv("C7_Birdnest.csv")
C7_Birdnest$Length <- as.double(C7_Birdnest$Length)
C7_Birdnest$Closed. <- as.double(C7_Birdnest$Closed.)
birdnest <- data.frame(length = C7_Birdnest$Length, closed = C7_Birdnest$Closed.)
birdnest
# load renamed dataset from personal library
C7_Birdnest <- read.csv("C7_Birdnest.csv")
C7_Birdnest$Length <- as.double(C7_Birdnest$Length)
C7_Birdnest$Closed. <- as.double(C7_Birdnest$Closed.)
birdnest <- na.omit(data.frame(length = C7_Birdnest$Length, closed = C7_Birdnest$Closed.))
birdnest
Cancer <- read.csv("C7 Cancer2.csv")
variable.names(Cancer)
Cancer <- read.csv("C7_Cancer2.csv")
data(lexdec)
library(tidyverse)
install.packages("dplyr")
install.packages("dplyr")
install.packages("dplyr")
install.packages("dplyr")
install.packages("dplyr")
library(tidyverse)
library(languageR)
library(lme4)
library(tidyverse)
data(lexdec)
force(lexdec)
View(lexdec)
theme_set(theme_bw())
table(lexdec$RT)
ggplot(lexdec, aes(x=RT)) +
geom_histogram()  +
xlab("Log-transformed reaction time") +
ylab("Number of cases")
summary(lexdec)
?lexdec
ggplot(lexdec, aes(x=RT,fill=NativeLanguage)) +
geom_histogram(position="identity",alpha=.5) +
xlab("Log-transformed reaction time") +
ylab("Number of cases")
mean(RT)
mean_se(RT)
mean_se(lexdec.RT)
```{r}
ggplot(lexdec, aes(x=RT)) +
geom_histogram()  +
xlab("Log-transformed reaction time") +
ylab("Number of cases")
ggplot(lexdec, aes(x=RT,fill=NativeLanguage)) +
geom_histogram(position="identity",alpha=.5) +
xlab("Log-transformed reaction time") +
ylab("Number of cases")
ggplot(lexdec, aes(x=RT,fill=NativeLanguage)) +
#geom_histogram(position="identity",alpha=.5) +
xlab("Log-transformed reaction time") +
ylab("Number of cases")
ggplot(lexdec, aes(x=RT,fill=NativeLanguage)) +
geom_histogram(position="identity",alpha=.5) +
xlab("Log-transformed reaction time") +
ylab("Number of cases")
ggplot(lexdec, aes(x=RT,fill=NativeLanguage)) +
geom_histogram(position="identity",alpha=1) +
xlab("Log-transformed reaction time") +
ylab("Number of cases")
ggplot(lexdec, aes(x=RT,fill=NativeLanguage)) +
geom_histogram(position="identity",alpha=.5) +
xlab("Log-transformed reaction time") +
ylab("Number of cases")
ggplot(lexdec, aes(x=RT,fill=NativeLanguage)) +
geom_density(alpha=.5) +
xlab("Log-transformed reaction time") +
ylab("Number of cases")
ggsave(file="graphs/rt_histogram.pdf",width=5,height=4)
ggplot(lexdec, aes(x=RT,fill=NativeLanguage)) +
geom_density(alpha=.5) +
xlab("Log-transformed reaction time") +
ylab("Number of cases")
helpt(ggsave)
help(ggsave)
ggplot(lexdec, aes(x=RT,fill=NativeLanguage)) +
geom_density(alpha=.5) +
xlab("Log-transformed reaction time") +
ylab("Number of cases")
ggsave(file="graphs/rt_histogram.pdf",width=5,height=4)
ggsave(file="graphs/rt_histogram.pdf",width=5,height=4)
ggplot(lexdec, aes(x=Frequency,y=RT)) +
geom_point() +
geom_smooth(method="lm")
ggplot(lexdec, aes(x=Frequency,y=RT)) +
geom_point() +
geom_smooth(method="lm") +
facet_wrap(~Subject)
ggplot(lexdec, aes(x=Frequency,y=RT,color=NativeLanguage)) +
geom_smooth(method="lm") +
geom_point() +
# geom_hline(yintercept=mean_rt,linetype="dashed",color="red") +
ylab("Log-transformed reaction time") +
xlab("Log-transformed CELEX lemma frequency") +
scale_color_manual(name="Native language",values=wes_palette("Zissou1")[2:3]) +
theme(legend.position="bottom")
?geom_smooth
library(wesanderson)
ggplot(lexdec, aes(x=Frequency,y=RT,color=NativeLanguage)) +
geom_smooth(method="lm") +
geom_point() +
# geom_hline(yintercept=mean_rt,linetype="dashed",color="red") +
ylab("Log-transformed reaction time") +
xlab("Log-transformed CELEX lemma frequency") +
scale_color_manual(name="Native language",values=wes_palette("Zissou1")[2:3]) +
theme(legend.position="bottom")
ggplot(lexdec, aes(x=Frequency,y=RT,color=NativeLanguage)) +
geom_smooth(method="lm") +
geom_point() +
geom_hline(yintercept=mean_rt,linetype="dashed",color="red") +
ylab("Log-transformed reaction time") +
xlab("Log-transformed CELEX lemma frequency") +
scale_color_manual(name="Native language",values=wes_palette("Zissou1")[2:3]) +
theme(legend.position="bottom")
ggplot(lexdec, aes(x=Frequency,y=RT,color=NativeLanguage)) +
geom_smooth(method="lm") +
geom_point() +
# geom_hline(yintercept=mean_rt,linetype="dashed",color="red") +
ylab("Log-transformed reaction time") +
xlab("Log-transformed CELEX lemma frequency") +
scale_color_manual(name="Native language",values=wes_palette("Zissou1")[2:3]) +
theme(legend.position="bottom")
ggplot(lexdec, aes(x=Frequency,y=RT)) +
geom_point() +
geom_smooth(method="lm") +
facet_wrap(~NativeLanguage)
~Subject
ggplot(lexdec, aes(x=Frequency,y=RT)) +
geom_point() +
geom_smooth(method="lm") +
facet_wrap(~Subject)
ggplot(agr, aes(x=NativeLanguage,y=MeanRT)) +
geom_bar(stat="identity",color="black",fill="gray60") +
geom_jitter(data=lexdec,aes(y=rawRT),alpha=.2,color="lightblue") +
geom_errorbar(aes(ymin=YMin,ymax=YMax),width=.25)
agr = lexdec %>%
group_by(NativeLanguage) %>%
summarize(MeanRT = mean(rawRT), CI.Low = ci.low(rawRT), CI.High = ci.high(rawRT)) %>%
mutate(YMin = MeanRT - CI.Low, YMax = MeanRT + CI.High)
lexdec$rawRT = exp(lexdec$RT)
agr = lexdec %>%
group_by(NativeLanguage) %>%
summarize(MeanRT = mean(rawRT), CI.Low = ci.low(rawRT), CI.High = ci.high(rawRT)) %>%
mutate(YMin = MeanRT - CI.Low, YMax = MeanRT + CI.High)
?ci.low
??ci.low
ggplot(lexdec, aes(x=Frequency,y=RT,color=NativeLanguage)) +
geom_point() +
geom_smooth(method="lm") +
# geom_hline(yintercept=mean_rt,linetype="dashed",color="red") +
ylab("Log-transformed reaction time") +
xlab("Log-transformed CELEX lemma frequency") +
scale_color_manual(name="Native language",values=wes_palette("Zissou1")[2:3]) +
theme(legend.position="bottom")
?confint.default
?ci
??ci
agr = lexdec %>%
group_by(NativeLanguage) %>%
summarize(MeanRT = mean(rawRT), CI.Low = ci.low(rawRT), CI.High = ci.high(rawRT)) %>%
mutate(YMin = MeanRT - CI.Low, YMax = MeanRT + CI.High)
?summarize
install.packages('bootstrap')
ggplot(agr, aes(x=NativeLanguage,y=MeanRT)) +
geom_bar(stat="identity",color="black",fill="gray60") +
geom_jitter(data=lexdec,aes(y=rawRT),alpha=.2,color="lightblue") +
geom_errorbar(aes(ymin=YMin,ymax=YMax),width=.25)
??agr
agr = lexdec %>%
group_by(NativeLanguage) %>%
summarize(MeanRT = mean(rawRT), CI.Low = ci.low(rawRT), CI.High = ci.high(rawRT)) %>%
mutate(YMin = MeanRT - CI.Low, YMax = MeanRT + CI.High)
install.packages('bootstrap')
install.packages(bootstrap)
install.packages("bootstrap")
library(bootstrap)
ggplot(lexdec, aes(x=Frequency,y=RT,color=NativeLanguage)) +
geom_point() +
geom_smooth(method="lm") +
# geom_hline(yintercept=mean_rt,linetype="dashed",color="red") +
ylab("Log-transformed reaction time") +
xlab("Log-transformed CELEX lemma frequency") +
scale_color_manual(name="Native language",values=wes_palette("Zissou1")[2:3]) +
theme(legend.position="bottom")
ggplot(agr, aes(x=NativeLanguage,y=MeanRT)) +
geom_bar(stat="identity",color="black",fill="gray60") +
geom_jitter(data=lexdec,aes(y=rawRT),alpha=.2,color="lightblue") +
geom_errorbar(aes(ymin=YMin,ymax=YMax),width=.25)
lexdec$rawRT = exp(lexdec$RT)
agr = lexdec %>%
group_by(NativeLanguage) %>%
summarize(MeanRT = mean(rawRT), CI.Low = ci.low(rawRT), CI.High = ci.high(rawRT)) %>%
mutate(YMin = MeanRT - CI.Low, YMax = MeanRT + CI.High)
source("helpers.R")
lexdec$rawRT = exp(lexdec$RT)
agr = lexdec %>%
group_by(NativeLanguage) %>%
summarize(MeanRT = mean(rawRT), CI.Low = ci.low(rawRT), CI.High = ci.high(rawRT)) %>%
mutate(YMin = MeanRT - CI.Low, YMax = MeanRT + CI.High)
ggplot(agr, aes(x=NativeLanguage,y=MeanRT)) +
geom_bar(stat="identity",color="black",fill="gray60") +
geom_jitter(data=lexdec,aes(y=rawRT),alpha=.2,color="lightblue") +
geom_errorbar(aes(ymin=YMin,ymax=YMax),width=.25)
ggplot(lexdec, aes(NativeLanguage,y=rawRT,fill=NativeLanguage)) +
geom_violin() +
geom_point(data=means,aes(y=Mean))
means = lexdec %>%
group_by(NativeLanguage) %>%
summarize(Mean=mean(rawRT))
ggplot(lexdec, aes(NativeLanguage,y=rawRT,fill=NativeLanguage)) +
geom_violin() +
geom_point(data=means,aes(y=Mean))
ggplot(lexdec, aes(NativeLanguage,y=rawRT)) +
geom_boxplot()
lexdec$PredictedRT = fitted(m)
m = lmer(RT ~ Frequency*NativeLanguage + FamilySize + (1+Frequency+FamilySize|Subject) + (1+NativeLanguage|Word),data=lexdec)
lexdec$PredictedRT = fitted(m)
ggplot(lexdec, aes(x=PredictedRT,y=RT)) +
geom_point(size=.5) +
xlab("Model predicted log response times") +
ylab("Empirical log response times")
install.packages("brms")
install.packages("RcppEigen")
install.packages("brms", dependencies = TRUE, INSTALL_opts = '--no-lock')
install.packages("mice", dependencies = TRUE, INSTALL_opts = '--no-lock')
install.packages("mice", dependencies = TRUE, INSTALL_opts = '--no-lock')
install.packages("mice", dependencies = TRUE, INSTALL_opts = '--no-lock')
remove.packages("rstan")
if (file.exists(".RData")) file.remove(".RData")
install.packages("rstan")
install.packages("rstan")
install.packages("rstan")
library(brms)
install.packages("brms")
?install.packages
install.packages("brms", dependencies = TRUE)
install.packages("brms", dependencies = TRUE)
library(brm)
library(rstan)
library(rstantools)
install.packages("rstan")
install.packages("brms")
install.packages("RcppEigen")
install.packages("StanHeaders")
install.packages("brms")
install.packages("brms")
install.packages("Brobdingnag")
install.packages("Brobdingnag")
install.packages("Brobdingnag")
theme_set(theme_bw())
# Load the `languageR` and `brms` packages. If they're not yet installed you'll get an error saying "Error in library(languageR) : there is no package called ‘languageR’". To install the package, first type and execute `install.packages("languageR")`. (This generalizes to any package, using the name of the package instead of "languageR".)
library(languageR)
library(tidyverse)
theme_set(theme_bw())
# This will also load the lexical decision time dataset from Baayen et al (2006), which we will be modeling extensively. To see two different summaries of the dataset and the first few lines:
summary(lexdec)
str(lexdec)
head(lexdec)
View(lexdec)
# Load the `languageR` and `brms` packages. If they're not yet installed you'll get an error saying "Error in library(languageR) : there is no package called ‘languageR’". To install the package, first type and execute `install.packages("languageR")`. (This generalizes to any package, using the name of the package instead of "languageR".)
library(languageR)
library(tidyverse)
theme_set(theme_bw())
# This will also load the lexical decision time dataset from Baayen et al (2006), which we will be modeling extensively. To see two different summaries of the dataset and the first few lines:
summary(lexdec)
str(lexdec)
head(lexdec)
View(lexdec)
# To get information about the dataset provided by the authors:
?lexdec
# 1. How many data points are there?
# Hint: use the nrow() function.
nrow(lexdec)
# 2. How many unique participants are there?
# Hint: Use the length() and unique() functions.
length(unique(lexdec$Subject))
# Let's recode the language background variable from "NativeLanguage" to "LanguageBackground", and its levels from "English" & "Other" to "English" & "Non-English"
lexdec = lexdec %>%
rename("LanguageBackground"="NativeLanguage") %>%
mutate(LanguageBackground = fct_recode(LanguageBackground, "Non-English"="Other"))
# 4. How many data points are in the English and Non-English groups?
# Hint: Use the table() function.
table(lexdec$LanguageBackground)
contrasts(lexdec$LanguageBackground)
lexdec %>%
group_by(LanguageBackground) %>% summarize (Mean = mean(RT))
# Frequentist stats
# Let's run our first linear regression model! We start by asking whether language background has a linear effect on log RTs:
m.f = lm(RT ~ LanguageBackground, data=lexdec)
summary(m.f)
# Bayesian stats
# Let's run the exact same model the Bayesian way! We haven't specified a prior, so the model will assume flat default priors.
m.b = brm(RT ~ LanguageBackground, data=lexdec)
summary(m.b)
# To see the assumed priors:
prior_summary(m.b)
# To do hypothesis-testing: get the Bayes Factor for the effect of LanguageBackground being greater than 0. (Evid.Ratio shows the Bayes Factor.)
h <- hypothesis(m.b, "LanguageBackgroundNonMEnglish > 0")
source("~/Documents/STANFORD/WI_24/Methods/LINGUIST245B/code_sheets/1_linear_regression_withprompts.R")
# 5. Extend the simple model to include an additional predictor for frequency. If you don't remember the name of the frequency column in the dataset, use the names() function.
m.f = lm(RT ~ LanguageBackground + Frequency, data = lexdec)
summary(m.f)
# 6. Let's extend the model to include the interaction between frequency and language background. In order to interpret interaction terms, we need to know how predictors are coded. By default, R dummy-codes categorical predictors. It assigns 0 and 1 to the predictors in alphabetical order. If you're not sure how a predictor is coded (or if you want to change the default coding), you can use the contrasts() function. What is the reference level for the LanguageBackground predictor?
contrasts(lexdec$LanguageBackground)
# Frequentist:
m.f = lm(RT ~ Frequency + LanguageBackground + Frequency:LanguageBackground, data=lexdec)
summary(m.f)
# CENTER PREDICTORS
tmp = lexdec %>%
mutate(cFrequency = Frequency - mean(Frequency),
cLanguageBackground = as.numeric(as.factor(LanguageBackground)) - mean(as.numeric(as.factor(LanguageBackground))))
contrasts(tmp$LanguageBackground)
View(tmp)
m.f = lm(RT ~ cFrequency*cLanguageBackground, data=tmp)
summary(m.f)
library(languageR)
library(lme4)
library(MuMIn)
install.packages("MuMIn")
library(languageR)
library(tidyverse)
library(lme4)
library(MuMIn)
# Preliminaries: Let's recode the language background variable and then create a column with centered predictors.
lexdec = lexdec %>%
rename("LanguageBackground"="NativeLanguage") %>%
mutate(LanguageBackground = fct_recode(LanguageBackground, "Non-English"="Other"))
theme_set(theme_bw())
View(lexdec)
lexdec = lexdec %>%
mutate(cFrequency = Frequency - mean(Frequency),
cLanguageBackground = as.numeric(as.factor(LanguageBackground)) - mean(as.numeric(as.factor(LanguageBackground))))
# Preliminaries: Let's recode the language background variable and then create a column with centered predictors.
lexdec = lexdec %>%
rename("LanguageBackground"="NativeLanguage") %>%
mutate(LanguageBackground = fct_recode(LanguageBackground, "Non-English"="Other"))
lexdec = lexdec %>%
mutate(cFrequency = Frequency - mean(Frequency),
cLanguageBackground = as.numeric(as.factor(LanguageBackground)) - mean(as.numeric(as.factor(LanguageBackground))))
library(tidyverse)
library(lme4)
library(lmerTest)
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
getwd
getwd(dirname)
setwd("/Users/gracebrown/Documents/STANFORD/WI_24/Methods/ling245b/245B-project/data")
read.csv("masc_lex-merged.csv")
lex <- read.csv("masc_lex-merged.csv")
View(lex)
summary(lex)
head(lex$response)
demo <- filter(lex, "trial_type" = "survey")
demo <- filter(lex, "trial_type" == "survey")
View(demo)
demo <- filter(lex, trial_type == "survey")
demo <- filter(lex, trial_type == c("survey", "survey-likert")
)
